# Interpretable-ML
This repository will house the materials I used while completing the guided project on Coursera on Interpretable Machine Learning Applications Part 1

Link - (https://www.coursera.org/projects/interpretable-machine-learning-applications-part-1)

The Python code uses the ELI5 library that provides explainability frameworks for black-box models. The Permutation Importance feature is used to provide the most explainable features for decision tree and random forests. 

***Permutation Feature Importance***

In prediction problems, not all features have equal importance. Certain features are more instrumental in determining the value of the outcome variable. In contexts of use of machine learning models for decision making, an inight into which features are more important for predictions helps to increase the interpretability and trustworthiness of the model.

## Heading 2

**References**
1. [Kaggle] (https://www.kaggle.com/dansbecker/permutation-importance)
